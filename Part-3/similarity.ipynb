{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mercado Libre Tech Challenge Part 3: Products Simularity\n",
    "\n",
    "### Objetive: find similarity between product titles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import umap\n",
    "import umap.plot\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "\n",
    "\n",
    "def clean_dataset(\n",
    "    data: pd.DataFrame,\n",
    "    check_only: bool = True,\n",
    "    dup_cols: list = [],\n",
    "    nan_cols: list = [],\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    # Check raw dataset info\n",
    "    print(f\"Raw dataset info:\\n\")\n",
    "    print(f\"{data.info()}\\n\")\n",
    "    # Check duplicates\n",
    "    if len(dup_cols) > 0:\n",
    "        for col in dup_cols:\n",
    "            print(\n",
    "                f\"Number of duplicates in column {col}: {data.duplicated(subset=[col]).sum()}\\n\"\n",
    "            )\n",
    "\n",
    "    if not check_only:\n",
    "        # Drop NaNs\n",
    "        data.dropna(subset=nan_cols, inplace=True)\n",
    "        # Drop duplicates\n",
    "        data.drop_duplicates(subset=dup_cols, inplace=True)\n",
    "\n",
    "        # Check dataset info after cleaning\n",
    "        print(f\"Cleaned dataset info:\\n\")\n",
    "        print(f\"{data.info()}\\n\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def transform_data_lowecase(data: pd.DataFrame, lower_cols: list = []) -> pd.DataFrame:\n",
    "\n",
    "    if len(lower_cols) > 0:\n",
    "        for col in lower_cols:\n",
    "            data[f\"{col}\"] = data[col].apply(lambda x: x.lower())\n",
    "    else:\n",
    "        print(\"No column to lower case was specifed. The dataframe won't be modified\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def keep_alpha(text: str) -> str:\n",
    "\n",
    "    return \" \".join(x for x in text.split(\" \") if (x.isalpha() or \":\" in x))\n",
    "\n",
    "\n",
    "def clean_text(text: str, rm_words: list, min_word_len: int = 0) -> str:\n",
    "\n",
    "    if len(rm_words) > 0:\n",
    "        for w in rm_words:\n",
    "            text = text.replace(w, \" \")\n",
    "    # else:\n",
    "    #     print(\"No words to remove were specified.\")\n",
    "    text = \" \".join(x for x in text.split(\" \") if len(x) > min_word_len)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def dim_reduction(\n",
    "    embeddings_matrix,\n",
    "    umap_config: dict,\n",
    "    random_init: int = 124,\n",
    "):\n",
    "    \"\"\"Use UMAP to reduce embeddings dimensionality\n",
    "\n",
    "    Args:\n",
    "        embeddings_matrix (numpy array): matrix with embeddings as rows\n",
    "        umap_config (dict): umap config options\n",
    "        random_init (int, optional): random initialization. Defaults to 124.\n",
    "\n",
    "    Returns:\n",
    "        UMAP object\n",
    "    \"\"\"\n",
    "    red_embeddings = None\n",
    "    red_embeddings = umap.UMAP(\n",
    "        n_neighbors=umap_config[\"n_neighbors\"],\n",
    "        n_components=umap_config[\"n_components\"],\n",
    "        metric=umap_config[\"metric\"],\n",
    "        min_dist=umap_config[\"min_dist\"],\n",
    "        random_state=random_init,\n",
    "    ).fit(embeddings_matrix)\n",
    "\n",
    "    return red_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load language model\n",
    "Different language models could be used here, in particular, multilingual models might be desired, considering item titles are in portuguese. Herein I tested two: `paraphrase-MiniLM-L6-v2` and `paraphrase-multilingual-mpnet-base-v2`. The latter is indeed a multilingual model, but more expensive in terms of embedding lenght and computational effort to compute the embeddings. Alternatively, `paraphrase-MiniLM-L6-v2` is smaller and faster to compute, and based on a preliminary evaluation (rapid visual inspection) of results, it gave better results than `paraphrase-multilingual-mpnet-base-v2`, for the puropose of the present task. For that herein we'll use `paraphrase-MiniLM-L6-v2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "# model = SentenceTransformer(\"paraphrase-multilingual-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data\"\n",
    "data_file_name = \"items_titles.csv\"\n",
    "query_file_name = \"items_titles_test.csv\"\n",
    "data = pd.read_csv(f\"{data_path}/{data_file_name}\")\n",
    "data_q = pd.read_csv(f\"{data_path}/{query_file_name}\")\n",
    "\n",
    "TEXT_EMBED_COL = \"ITE_ITEM_TITLE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw dataset info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 1 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   ITE_ITEM_TITLE  30000 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 234.5+ KB\n",
      "None\n",
      "\n",
      "Number of duplicates in column ITE_ITEM_TITLE: 0\n",
      "\n",
      "Cleaned dataset info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30000 entries, 0 to 29999\n",
      "Data columns (total 1 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   ITE_ITEM_TITLE  30000 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 468.8+ KB\n",
      "None\n",
      "\n",
      "Dataset sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITE_ITEM_TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25665</th>\n",
       "      <td>kit de tênis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16464</th>\n",
       "      <td>tênis infantil feminino krisle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22386</th>\n",
       "      <td>tenis dg sorrento preto black unissex dourado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10149</th>\n",
       "      <td>bicicleta com suspensão aro full velocidades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>tênis drop gel equation feminino preto original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25295</th>\n",
       "      <td>tênis olympikus index masculino academia fitness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8876</th>\n",
       "      <td>sapatênis linha moderno conforto doctor flex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12348</th>\n",
       "      <td>tenis infantil feminino original super leve ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3858</th>\n",
       "      <td>tênis feminino academia esporte caminhada reló...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19209</th>\n",
       "      <td>kit pares sapatenis casual barato corrente e ó...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          ITE_ITEM_TITLE\n",
       "25665                                       kit de tênis\n",
       "16464                     tênis infantil feminino krisle\n",
       "22386      tenis dg sorrento preto black unissex dourado\n",
       "10149       bicicleta com suspensão aro full velocidades\n",
       "8729     tênis drop gel equation feminino preto original\n",
       "25295   tênis olympikus index masculino academia fitness\n",
       "8876        sapatênis linha moderno conforto doctor flex\n",
       "12348  tenis infantil feminino original super leve ca...\n",
       "3858   tênis feminino academia esporte caminhada reló...\n",
       "19209  kit pares sapatenis casual barato corrente e ó..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Processing training dataset\n",
    "data = clean_dataset(data=data, dup_cols=[TEXT_EMBED_COL], nan_cols=[TEXT_EMBED_COL], check_only=False)\n",
    "data = transform_data_lowecase(data, lower_cols=[TEXT_EMBED_COL])\n",
    "data[TEXT_EMBED_COL] = data[TEXT_EMBED_COL].transform(lambda x: keep_alpha(x))\n",
    "\n",
    "print(\"Dataset sample:\")\n",
    "display(data.sample(10, random_state=123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw dataset info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 0 to 9999\n",
      "Data columns (total 1 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   ITE_ITEM_TITLE  10000 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 156.2+ KB\n",
      "None\n",
      "\n",
      "Number of duplicates in column ITE_ITEM_TITLE: 146\n",
      "\n",
      "Cleaned dataset info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9854 entries, 0 to 9999\n",
      "Data columns (total 1 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   ITE_ITEM_TITLE  9854 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 154.0+ KB\n",
      "None\n",
      "\n",
      "Query sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITE_ITEM_TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>under armour hovr phantom conexão bluetooth tê...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7783</th>\n",
       "      <td>bicicleta bike infantil aro nathor candy envio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>tênis masculino olympikus amortecedor corrida ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>tênis casual feminino elástico kolosh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7818</th>\n",
       "      <td>tênis de treino masculino under armour hovr apex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5453</th>\n",
       "      <td>sapatênis masculino zíper hankook macio confor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>tênis usthemp chunky smooth bulldog inglês car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6002</th>\n",
       "      <td>tênis feminino diversas cores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>tênis ramarim feminino chunky branco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6611</th>\n",
       "      <td>sapatênis pegada casual couro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ITE_ITEM_TITLE\n",
       "7     under armour hovr phantom conexão bluetooth tê...\n",
       "7783     bicicleta bike infantil aro nathor candy envio\n",
       "2157  tênis masculino olympikus amortecedor corrida ...\n",
       "2362              tênis casual feminino elástico kolosh\n",
       "7818   tênis de treino masculino under armour hovr apex\n",
       "5453  sapatênis masculino zíper hankook macio confor...\n",
       "2067  tênis usthemp chunky smooth bulldog inglês car...\n",
       "6002                      tênis feminino diversas cores\n",
       "369                tênis ramarim feminino chunky branco\n",
       "6611                      sapatênis pegada casual couro"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Processing query dataset\n",
    "data_q = clean_dataset(data=data_q, dup_cols=[TEXT_EMBED_COL], nan_cols=[TEXT_EMBED_COL], check_only=False)\n",
    "data_q = transform_data_lowecase(data_q, lower_cols=[TEXT_EMBED_COL])\n",
    "data_q[TEXT_EMBED_COL] = data_q[TEXT_EMBED_COL].transform(lambda x: keep_alpha(x))\n",
    "\n",
    "print(\"Query sample:\")\n",
    "display(data_q.sample(10, random_state=123))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate numerical vector representations from text (embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = model.encode(data[TEXT_EMBED_COL].to_list())\n",
    "embeddings_q = model.encode(data_q[TEXT_EMBED_COL].to_list())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "The present work requires searching for similar items (embeddings) in a dataset of 10K item titles, not in the 30K, thus an exact brute force indexing method (`IndexFlatL2`) is the best option. If dealing with the larger 30K or higher, then a brute force approach would become unfeasible, an alternative indexing method (e.g. HNSW) should be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings size: 384\n",
      "Index size: 10000\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = embeddings_q.shape[1]\n",
    "print(f\"Embeddings size: {embedding_dim}\")\n",
    "\n",
    "# Build index & add embeddings\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "index.add(embeddings_q)\n",
    "\n",
    "print(f\"Index size: {index.ntotal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search top 10 most similar embeddings (neighbours) to each embedding in the dataset\n",
    "num_neigbours = 10\n",
    "distance, neighbors = index.search(embeddings_q, num_neigbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbour ids:\n",
      " [[   0 1767 6155  309 7880 7922  792 1559 5382 1847]\n",
      " [   1 4385 9523 1779 2346 5962 2925 5018 2972 3778]\n",
      " [   2 8528 4539 6670 6233 9759 4331 3107 7533 3250]\n",
      " [   3  115 7037 9997 8953  214 7936 2715 2133 5653]\n",
      " [   4 4396 3796 9477 5522 2853 8168 4515 4526  761]]\n",
      "\n",
      "Neighbour distance:\n",
      " [[0.0000000e+00 1.2596882e+01 1.3523090e+01 1.3642517e+01 1.5268101e+01\n",
      "  1.5412693e+01 1.6024605e+01 1.6658463e+01 1.6685265e+01 1.7257355e+01]\n",
      " [1.5258789e-05 1.4231960e+01 1.4446102e+01 1.5067076e+01 1.5171703e+01\n",
      "  1.5330662e+01 1.5891640e+01 1.6217333e+01 1.6476946e+01 1.6511831e+01]\n",
      " [1.1444092e-05 1.1374603e+01 1.1959545e+01 1.3136986e+01 1.5434505e+01\n",
      "  1.6515198e+01 1.6974964e+01 2.0170223e+01 2.0693367e+01 2.0940525e+01]\n",
      " [0.0000000e+00 6.8527985e+00 1.2840492e+01 1.5471779e+01 1.5780037e+01\n",
      "  1.6165329e+01 1.6622261e+01 1.6863075e+01 1.7503738e+01 1.8121620e+01]\n",
      " [7.6293945e-06 1.7027935e+01 1.8994801e+01 2.3655842e+01 2.3842819e+01\n",
      "  2.4805038e+01 2.4938644e+01 2.5049374e+01 2.5210014e+01 2.5226002e+01]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITE_ITEM_TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tênis Olympikus Esporte Valente - Masculino Kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>Tênis Infantil Masculino Olympikus 943 Supremo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6155</th>\n",
       "      <td>Tênis Esportivo Infantil Masc Olympikus Maneir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Tênis Masculino Olympikus Enjoy Kids/726 - Inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7880</th>\n",
       "      <td>Tênis Infantil Olympikus Maneiro Kids 942 Mari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7922</th>\n",
       "      <td>Tênis Olympikus Masculino Valente - Kids Infan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>Tênis Infantil Masculino Olympikus Valente Azu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>Tênis Esportivo Infantil Olympikus Azul Marinh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5382</th>\n",
       "      <td>Tênis Masculino Esportivo Confortável Olympik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>Tênis Masculino Esportivo Confortavél Olympiku...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ITE_ITEM_TITLE\n",
       "0      Tênis Olympikus Esporte Valente - Masculino Kids\n",
       "1767  Tênis Infantil Masculino Olympikus 943 Supremo...\n",
       "6155  Tênis Esportivo Infantil Masc Olympikus Maneir...\n",
       "309   Tênis Masculino Olympikus Enjoy Kids/726 - Inf...\n",
       "7880  Tênis Infantil Olympikus Maneiro Kids 942 Mari...\n",
       "7922  Tênis Olympikus Masculino Valente - Kids Infan...\n",
       "792   Tênis Infantil Masculino Olympikus Valente Azu...\n",
       "1559  Tênis Esportivo Infantil Olympikus Azul Marinh...\n",
       "5382   Tênis Masculino Esportivo Confortável Olympik...\n",
       "1847  Tênis Masculino Esportivo Confortavél Olympiku..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check out some examples\n",
    "print(f\"Neighbour ids:\\n {neighbors[:5]}\\n\")\n",
    "print(f\"Neighbour distance:\\n {distance[:5]}\\n\")\n",
    "display(data_q.iloc[neighbors[0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = data_q[\"ITE_ITEM_TITLE\"].to_list()\n",
    "item_df_list = []\n",
    "for i,x in enumerate(items):\n",
    "    item_df = pd.DataFrame()\n",
    "    \n",
    "    item = np.repeat(x, len(neighbors[i]))\n",
    "    similar_items = data_q.iloc[neighbors[i]][\"ITE_ITEM_TITLE\"].values\n",
    "    scores = distance[i]\n",
    "    \n",
    "    item_df[\"ITE_ITEM_TITLE\"] = item\n",
    "    item_df[\"SIMILAR_ITEMS\"] = similar_items\n",
    "    item_df[\"SCORES\"] = scores\n",
    "    \n",
    "    item_df_list.append(item_df)\n",
    "\n",
    "similarity_df = pd.concat(item_df_list)\n",
    "similarity_df.to_csv(\"output.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Item titles embeddings using a language (`paraphrase-MiniLM-L6-v2`) model and indexing (faiss `IndexFlatL2`) were applied to generate the list of most similat items for each of the item in the dataset `items_titles_test.csv`.\n",
    "- Although the obtained results are good from an initial visual inspection, a more thourough analysis of results, possibly manually annotating some exmaples and measuring the recall would be useful to no only confirm the quality of the obtained results, but also to compare with other language models and indexing methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1d7b31c50be00e0ebc7930a7fe34b52cfd6fb16a2569109794ee8dca210535d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
